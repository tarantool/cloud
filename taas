#!/usr/bin/env python
from __future__ import print_function

import mimetypes
import random
import string
import argparse
import json
import logging
import sys
import os
import urllib
import urllib2
import base64
import collections
import tarfile
import StringIO
import re
import copy

try:
    from ConfigParser import SafeConfigParser
except ImportError:
    from configparser import SafeConfigParser

SETTINGS_PATH = os.path.expanduser('~/.taas.cfg')

GROUP_KEY_ORDER = ["id", "creation_time", "name", "type", "memsize"]

_BOUNDARY_CHARS = string.digits + string.ascii_letters

class termcolors:
    HEADER = '\033[95m'
    OKBLUE = '\033[94m'
    OKGREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'

def color_string(string, color):
    return color + string + termcolors.ENDC

def strip_ansi(string):
    """Returns string with ansi color codes stripped"""
    ansi_escape = re.compile(r'\x1b[^m]*m')
    return ansi_escape.sub('', string)

def visible_len(string):
    """Returns length of string without ansi escape codes"""
    ansi_escape = re.compile(r'\x1b[^m]*m')
    return len(ansi_escape.sub('', string))


class MultipartData(object):
    def __init__(self, fields, files, boundary=None, progress=None):
        self.progress_callback = progress

        def escape_quote(s):
            return s.replace('"', '\\"')

        if boundary is None:
            boundary = ''.join(random.choice(_BOUNDARY_CHARS) for i in
                               range(30))
        lines = []

        for name, value in fields.items():
            lines.extend((
                '--{0}'.format(boundary),
                'Content-Disposition: form-data; name="{0}"'.format(
                    escape_quote(name)),
                '',
                str(value),
            ))

        for name, value in files.items():
            filename = value['filename']
            if 'mimetype' in value:
                mimetype = value['mimetype']
            else:
                mimetype = mimetypes.guess_type(filename)[0] or \
                           'application/octet-stream'
            lines.extend((
                '--{0}'.format(boundary),
                'Content-Disposition: form-data; name="{0}"; filename="{1}"'.format(
                    escape_quote(name), escape_quote(filename)),
                'Content-Type: {0}'.format(mimetype),
                '',
                value
            ))

        lines.extend((
            '--{0}--'.format(boundary),
            '',
        ))

        body_len = 0
        for entry in lines:
            if isinstance(entry, str):
                body_len += len(entry) + len('\r\n')
            elif 'length' in entry:
                body_len += entry['length'] + len('\r\n')
            else:
                raise RuntimeError("No length provided")

        body_len -= len('\r\n')

        self.body_len = body_len
        self.lines = lines

        headers = {
            'Content-Type': 'multipart/form-data; boundary={0}'.format(
                boundary),
            'Content-Length': str(body_len),
        }

        self.headers = headers
        self.buf = ""
        self.line = 0
        self.bytes_read = 0

    def progress(self):
        if self.progress_callback:
            self.progress_callback(float(self.bytes_read)/float(self.body_len))

    def read(self, num=-1):
        if num == -1:
            result = ""
            chunksize = 8192

            while True:
                bytes_read = self.read(chunksize)
                if len(bytes_read) == 0:
                    break
                result += bytes_read
            return result

        while True:
            if len(self.buf) >= num:
                result = self.buf[:num]
                self.buf = self.buf[num:]
                self.bytes_read += len(result)
                self.progress()
                return result

            if self.line >= len(self.lines):
                result = self.buf
                self.buf = ''
                self.bytes_read += len(result)
                self.progress()
                return result

            line = self.lines[self.line]

            if isinstance(line, str):
                self.buf += line
                self.line += 1
                if self.line < len(self.lines):
                    self.buf += '\r\n'
            else:
                fobj = line['content']

                to_read = num - len(self.buf)
                bytes_read = fobj.read(to_read)
                if len(bytes_read) == 0:
                    self.line += 1
                    if self.line < len(self.lines):
                        self.buf += '\r\n'

                else:
                    self.buf += bytes_read




def encode_multipart(fields, files, boundary=None):
    r"""Encode dict of form fields and dict of files as multipart/form-data.
    Return tuple of (body_string, headers_dict). Each value in files is a dict
    with required keys 'filename' and 'content', and optional 'mimetype' (if
    not specified, tries to guess mime type or uses 'application/octet-stream').

    >>> body, headers = encode_multipart({'FIELD': 'VALUE'},
    ...                                  {'FILE': {'filename': 'F.TXT', 'content': 'CONTENT'}},
    ...                                  boundary='BOUNDARY')
    >>> print('\n'.join(repr(l) for l in body.split('\r\n')))
    '--BOUNDARY'
    'Content-Disposition: form-data; name="FIELD"'
    ''
    'VALUE'
    '--BOUNDARY'
    'Content-Disposition: form-data; name="FILE"; filename="F.TXT"'
    'Content-Type: text/plain'
    ''
    'CONTENT'
    '--BOUNDARY--'
    ''
    >>> print(sorted(headers.items()))
    [('Content-Length', '193'), ('Content-Type', 'multipart/form-data; boundary=BOUNDARY')]
    >>> len(body)
    193
    """
    def escape_quote(s):
        return s.replace('"', '\\"')

    if boundary is None:
        boundary = ''.join(random.choice(_BOUNDARY_CHARS) for i in range(30))
    lines = []

    for name, value in fields.items():
        lines.extend((
            '--{0}'.format(boundary),
            'Content-Disposition: form-data; name="{0}"'.format(escape_quote(name)),
            '',
            str(value),
        ))

    for name, value in files.items():
        filename = value['filename']
        if 'mimetype' in value:
            mimetype = value['mimetype']
        else:
            mimetype = mimetypes.guess_type(filename)[0] or 'application/octet-stream'
        lines.extend((
            '--{0}'.format(boundary),
            'Content-Disposition: form-data; name="{0}"; filename="{1}"'.format(
                    escape_quote(name), escape_quote(filename)),
            'Content-Type: {0}'.format(mimetype),
            '',
            value['content'],
        ))

    lines.extend((
        '--{0}--'.format(boundary),
        '',
    ))
    body = '\r\n'.join(lines)

    headers = {
        'Content-Type': 'multipart/form-data; boundary={0}'.format(boundary),
        'Content-Length': str(len(body)),
    }

    return (body, headers)


def print_upload_progress():
    def closure(fraction):
        notify_bin = int(fraction*20) * 5

        for val in range(closure.notified_bin, notify_bin, 5):
            print("%d %%" % (val + 5))
        closure.notified_bin = notify_bin

    closure.notified_bin = 0
    return closure

def print_upload_progress_silent():
    def closure(fraction):
        notify_bin = int(fraction*20) * 5

        for val in range(closure.notified_bin, notify_bin, 5):
            print('.', end='')
        closure.notified_bin = notify_bin

    closure.notified_bin = 0
    return closure


def print_table(header, data):
    lengths = [0] * len(header)

    if not sys.stdout.isatty():
        data = copy.deepcopy(data)
        for line in data:
            for key in line.keys():
                line[key] = strip_ansi(line[key])
    else:
        header = [(h[0], color_string(h[1], termcolors.HEADER)) for h in header]

    for idx, field in enumerate(header):
        maxlen = max([visible_len(d[field[0]])+1 for d in data] +
                     [visible_len(field[1]) + 4])
        lengths[idx] = maxlen

    real_lengths = [0] * len(header)
    for idx, field in enumerate(header):
        real_lengths[idx] = lengths[idx] + len(field[1]) - \
                            visible_len(field[1])

    fmt = " ".join('{!s:<%d}'%l for l in real_lengths).decode('utf-8')

    print(fmt.format(*[c[1] for c in header]))
    for entry in data:
        real_lengths = [0] * len(header)
        for idx, field in enumerate(header):
            real_lengths[idx] = lengths[idx] + len(entry[field[0]]) - \
                                visible_len(entry[field[0]])

        fmt = " ".join('{!s:<%d}'%l for l in real_lengths).decode('utf-8')
        print(fmt.format(*[entry[c[0]] for c in header]))


def add_http_prefix(url):
    """
    Add a http:// prefix to url if it doesn't start with http*://
    """
    if url.startswith('http://') or url.startswith('https://'):
        return url

    return 'http://' + url


def http_get(url, args=None, auth=None, cafile=None):
    if args:
        url = url + '?' + urllib.urlencode(args, True)

    request = urllib2.Request(url)
    if auth:
        base64string = base64.encodestring(
            '%s:%s' % (auth[0], auth[1])).replace('\n', '')
        request.add_header('Authorization', 'Basic %s' % base64string)

    response = urllib2.urlopen(request, cafile=cafile)
    response_text = response.read().decode('utf-8')

    return response.getcode(), response_text


def http_download(url, args=None, auth=None, cafile=None):
    if args:
        url = url + '?' + urllib.urlencode(args, True)

    request = urllib2.Request(url)
    if auth:
        base64string = base64.encodestring(
            '%s:%s' % (auth[0], auth[1])).replace('\n', '')
        request.add_header('Authorization', 'Basic %s' % base64string)

    response = urllib2.urlopen(request, cafile=cafile)

    return response.getcode(), response


def http_post(url, data, files=None, auth=None,
              cafile=None, progress_callback=None):
    if files:
        data = MultipartData(data, files, progress=progress_callback)
        headers = data.headers
    else:
        data = json.dumps(data)
        data_len = len(data)
        headers = {'Content-Type': 'application/json',
                   'Content-Length': data_len}

    request = urllib2.Request(
        url,
        data,
        headers
    )

    if auth:
        base64string = base64.encodestring(
            '%s:%s' % (auth[0], auth[1])).replace('\n', '')
        request.add_header('Authorization', 'Basic %s' % base64string)

    response = urllib2.urlopen(request, cafile=cafile)
    response_text = response.read()

    return response.getcode(), response_text.decode('utf-8')


def http_put(url, data, files=None, auth=None,
             cafile=None, progress_callback=None):
    if files:
        data = MultipartData(data, files, progress=progress_callback)
        headers = data.headers
    else:
        data = json.dumps(data)
        data_len = len(data)
        headers = {'Content-Type': 'application/json',
                   'Content-Length': data_len}

    request = urllib2.Request(
        url,
        data,
        headers
        )
    request.get_method = lambda: 'PUT'

    if auth:
        base64string = base64.encodestring(
            '%s:%s' % (auth[0], auth[1])).replace('\n', '')
        request.add_header('Authorization', 'Basic %s' % base64string)

    response = urllib2.urlopen(request, cafile=cafile)
    response_text = response.read()

    return response.getcode(), response_text.decode('utf-8')

def http_delete(url, data, auth=None, cafile=None):
    data_str = json.dumps(data)
    data_len = len(data_str)

    request = urllib2.Request(
        url,
        data_str,
        {'Content-Type': 'application/json',
         'Content-Length': data_len})
    request.get_method = lambda: 'DELETE'

    if auth:
        base64string = base64.encodestring(
            '%s:%s' % (auth[0], auth[1])).replace('\n', '')
        request.add_header('Authorization', 'Basic %s' % base64string)

    response = urllib2.urlopen(request, cafile=cafile)
    response_text = response.read()

    return response.getcode(), response_text.decode('utf-8')

def colorize_state(state_name, state_type):
    if state_type == 'passing':
        return color_string(state_name, termcolors.OKGREEN)
    elif state_type == 'warning':
        return color_string(state_name, termcolors.WARNING)
    else:
        return color_string(state_name, termcolors.FAIL)


def update_images_command(host, auth, cafile, verbose):
    url = '%s/api/update_images' % add_http_prefix(host)

    args = {'async': True}
    try:
        _, data_str = http_post(url, args, auth=auth, cafile=cafile)
    except urllib2.HTTPError, err:
        if err.code == 403:
            data = json.loads(err.read())
            print("Failed to run instance: %s" % data['message'])
            sys.exit(1)
        elif err.code == 401:
            print("Authorization required")
            sys.exit(1)
        else:
            raise

    data = json.loads(data_str)

    task_id = data['task_id']

    status = "running"
    index = 0
    while status == "running":
        url = '%s/api/tasks/%s' % (add_http_prefix(host), task_id)
        args = {"index": index}
        try:
            _, data_str = http_get(url, args, auth, cafile)
        except urllib2.HTTPError, err:
            if err.code == 401:
                print("Authorization required")
                sys.exit(1)
            else:
                raise
        data = json.loads(data_str)
        index = data['index']
        status = data['status']
        for log in data['logs']:
            if verbose:
                print(log['message'])
            else:
                print('.', end='')
                sys.stdout.flush()

        if status == "error":
            print("Error: %s" % data['message'])
            sys.exit(1)

    if not verbose:
        print('')


def ps_command(host, is_quiet, auth, cafile):
    url = '%s/api/groups' % add_http_prefix(host)

    try:
        _, data_str = http_get(url, None, auth, cafile)
    except urllib2.HTTPError, err:
        if err.code == 401:
            print("Authorization required")
            sys.exit(1)
        else:
            raise

    data = json.loads(data_str)

    result = []
    for group_id, group in data.items():
        for instance in group['instances']:
            if instance['mem_used'] is not None:
                mem_used = str(instance['mem_used'])
            else:
                mem_used = 'N/A'

            if instance['host'] is not None:
                host = instance['host']
            else:
                host = 'N/A'

            result.append({
                'group_id': color_string(group_id, termcolors.OKBLUE),
                'instance_num': instance['name'],
                'name': group['name'],
                'type': group['type'],
                'memsize': str(group['memsize']),
                'mem_used': mem_used,
                'state': colorize_state(instance['state']['name'],
                                        instance['state']['type']),
                'addr': instance['addr'],
                'port': str(instance['port']),
                'host': host,
                'date': group['creation_time'].split('T')[0],
                'time': group['creation_time'].split('.')[0]
            })

    result = sorted(result, key=lambda x: x['time'], reverse=True)

    header = [
        ('group_id', 'GROUP'),
        ('instance_num', 'INSTANCE #'),
        ('name', 'NAME'),
        ('type', 'TYPE'),
        ('memsize', 'SIZE'),
        ('mem_used', 'USED'),
        ('state', 'STATE'),
        ('addr', 'ADDRESS'),
        ('port', 'PORT'),
        ('host', 'NODE'),
        ('date', 'DATE')
    ]

    if not is_quiet:
        print_table(header, result)
    else:
        groups = set([i['group_id'] for i in result])
        print('\n'.join(groups))


def inspect_command(host, group_id_list, auth, cafile):
    result = []
    for group_id in group_id_list:
        url = '%s/api/groups/%s' % (add_http_prefix(host), group_id)
        data_str = None
        try:
            _, data_str = http_get(url, None, auth, cafile)
        except urllib2.HTTPError, err:
            if err.code == 404:
                print("No such group: '%s'" % group_id)
                sys.exit(1)
            elif err.code == 401:
                print("Authorization required")
                sys.exit(1)
            else:
                raise
        data = json.loads(data_str)

        # More important fields should be displayed on top
        ordered_data = collections.OrderedDict()
        keys = [k for k in GROUP_KEY_ORDER if k in data.keys()]
        keys = keys + [k for k in data.keys() if k not in keys]
        for key in keys:
            ordered_data[key] = data[key]
        result.append(ordered_data)
    print(json.dumps(result, indent=2))


def run_command(host, instance_type,
                name, memsize, password, auth, cafile, verbose):
    args = {'type': instance_type,
            'name': name or '',
            'memsize': memsize,
            'async': True}

    if password:
        args['password'] = password

    url = '%s/api/groups' % add_http_prefix(host)

    try:
        _, data_str = http_post(url, args, auth=auth, cafile=cafile)
    except urllib2.HTTPError, err:
        if err.code == 403:
            data = json.loads(err.read())
            print("Failed to run instance: %s" % data['message'])
            sys.exit(1)
        elif err.code == 401:
            print("Authorization required")
            sys.exit(1)
        else:
            raise

    data = json.loads(data_str)

    task_id = data['task_id']
    group_id = data['id']

    status = "running"
    index = 0
    while status == "running":
        url = '%s/api/tasks/%s' % (add_http_prefix(host), task_id)
        args = {"index": index}
        try:
            _, data_str = http_get(url, args, auth, cafile)
        except urllib2.HTTPError, err:
            if err.code == 401:
                print("Authorization required")
                sys.exit(1)
            else:
                raise
        data = json.loads(data_str)
        index = data['index']
        status = data['status']
        for log in data['logs']:
            if verbose:
                print(log['message'])
            else:
                print('.', end='')
                sys.stdout.flush()

        if status == "error":
            print("Error: %s" % data['message'])
            sys.exit(1)

    if not verbose:
        print('')

    print(group_id)

def rm_command(host, group_id_list, auth, cafile, verbose):
    for group_id in group_id_list:
        url = '%s/api/groups/%s' % (add_http_prefix(host), group_id)
        try:
            _, data_str = http_delete(url, {'async': True}, auth, cafile)
        except urllib2.HTTPError, err:
            if err.code == 404:
                print("No such group: '%s'" % group_id)
                sys.exit(1)
            elif err.code == 401:
                print("Authorization required")
                sys.exit(1)
            else:
                raise

        data = json.loads(data_str)
        task_id = data['task_id']

        status = "running"
        index = 0
        while status == "running":
            url = '%s/api/tasks/%s' % (add_http_prefix(host), task_id)
            args = {"index": index}
            try:
                _, data_str = http_get(url, args, auth, cafile)
            except urllib2.HTTPError, err:
                if err.code == 401:
                    print("Authorization required")
                    sys.exit(1)
                else:
                    raise
            data = json.loads(data_str)
            index = data['index']
            status = data['status']
            for log in data['logs']:
                if verbose:
                    print(log['message'])
                else:
                    print('.', end='')
                    sys.stdout.flush()

            if status == "error":
                print("Error: %s" % data['message'])
                sys.exit(1)

    if not verbose:
        print('')


def update_command(host, group_id, name, memsize, password, config, heal,
                   auth, cafile, verbose):
    data = {'async': True}
    files = None
    if heal:
        data['heal'] = True
    if name:
        data['name'] = name
    if memsize:
        data['memsize'] = memsize
    if password:
        data['password'] = password
    if config:
        config = os.path.expanduser(config)
        config = os.path.realpath(config)
        filedata = None
        if os.path.isdir(config):
            out = StringIO.StringIO()
            tar = tarfile.open(fileobj=out, mode="w:gz")
            tar.add(config, arcname=".")
            tar.close()
            filename = 'config.tar.gz'
            out.seek(0, os.SEEK_END)
            file_length = out.tell()
            out.seek(0)
            filedata = out
            is_dir = True
        else:
            filename = os.path.basename(config)
            file_length = os.path.getsize(config)
            filedata = open(config)
            is_dir = False

        files = {'config': {'filename': filename,
                            'content': filedata,
                            'length': file_length}}
        data['config_is_dir'] = is_dir

    url = '%s/api/groups/%s' % (add_http_prefix(host), group_id)

    try:
        _, data_str = http_put(url, data, files=files,
                               auth=auth, cafile=cafile)
    except urllib2.HTTPError, err:
        if err.code == 404:
            print("No such group: '%s'" % group_id)
            sys.exit(1)
        elif err.code == 401:
            print("Authorization required")
            sys.exit(1)
        else:
            raise

    data = json.loads(data_str)
    task_id = data['task_id']

    status = "running"
    index = 0
    while status == "running":
        url = '%s/api/tasks/%s' % (add_http_prefix(host), task_id)
        args = {"index": index}
        try:
            _, data_str = http_get(url, args, auth, cafile)
        except urllib2.HTTPError, err:
            if err.code == 401:
                print("Authorization required")
                sys.exit(1)
            else:
                raise
        data = json.loads(data_str)
        index = data['index']
        status = data['status']

        for log in data['logs']:
            if verbose:
                print(log['message'])
            else:
                print('.', end='')
                sys.stdout.flush()

        if status == "error":
            print("Error: %s" % data['message'])
            sys.exit(1)

    if not verbose:
        print('')

def upgrade_command(host, group_id, auth, cafile, verbose):
    data = {'async': True,
            'docker_image_name': 'tarantool-cloud-memcached'}

    url = '%s/api/groups/%s' % (add_http_prefix(host), group_id)

    try:
        _, data_str = http_put(url, data, auth=auth, cafile=cafile)
    except urllib2.HTTPError, err:
        if err.code == 404:
            print("No such group: '%s'" % group_id)
            sys.exit(1)
        elif err.code == 401:
            print("Authorization required")
            sys.exit(1)
        else:
            raise

    data = json.loads(data_str)
    task_id = data['task_id']

    status = "running"
    index = 0
    while status == "running":
        url = '%s/api/tasks/%s' % (add_http_prefix(host), task_id)
        args = {"index": index}
        try:
            _, data_str = http_get(url, args, auth, cafile)
        except urllib2.HTTPError, err:
            if err.code == 401:
                print("Authorization required")
                sys.exit(1)
            else:
                raise
        data = json.loads(data_str)
        index = data['index']
        status = data['status']
        for log in data['logs']:
            if verbose:
                print(log['message'])
            else:
                print('.', end='')
                sys.stdout.flush()

        if status == "error":
            print("Error: %s" % data['message'])
            sys.exit(1)

    if not verbose:
        print('')

def backup_command(host, group_id, auth, cafile, verbose):
    args = {'async': True}

    url = '%s/api/groups/%s/backups' % (add_http_prefix(host),
                                               group_id)

    try:
        _, data_str = http_post(url, args, auth=auth, cafile=cafile)
    except urllib2.HTTPError, err:
        if err.code == 500:
            data = json.loads(err.read())
            print("Failed to back up: %s" % data['message'])
            sys.exit(1)
        if err.code == 401:
            print("Authorization required")
            sys.exit(1)
        else:
            raise

    data = json.loads(data_str)

    task_id = data['task_id']
    backup_id = data.get('id', None)

    status = "running"
    index = 0
    while status == "running":
        url = '%s/api/tasks/%s' % (add_http_prefix(host), task_id)
        args = {"index": index}
        try:
            _, data_str = http_get(url, args, auth, cafile)
        except urllib2.HTTPError, err:
            if err.code == 500:
                data = json.loads(err.read())
                print("Failed to back up: %s" % data['message'])
                sys.exit(1)
            if err.code == 401:
                print("Authorization required")
                sys.exit(1)
            else:
                raise
        data = json.loads(data_str)
        index = data['index']
        status = data['status']
        for log in data['logs']:
            if verbose:
                print(log['message'])
            else:
                print('.', end='')
                sys.stdout.flush()

        if status == "error":
            print("Error: %s" % data['message'])
            sys.exit(1)

    if not verbose:
        print('')

    if backup_id:
        print(backup_id)


def restore_command(host, group_id, backup_id, auth, cafile, verbose):
    args = {'async': True,
            'backup_id': backup_id}

    url = '%s/api/groups/%s' % (add_http_prefix(host),
                                       group_id)

    try:
        _, data_str = http_put(url, args, auth=auth, cafile=cafile)
    except urllib2.HTTPError, err:
        if err.code == 500:
            data = json.loads(err.read())
            print("Failed to restore: %s" % data['message'])
            sys.exit(1)
        if err.code == 404:
            print("No such group: '%s'" % group_id)
            sys.exit(1)
        if err.code == 401:
            print("Authorization required")
            sys.exit(1)
        else:
            raise

    data = json.loads(data_str)
    task_id = data['task_id']

    status = "running"
    index = 0
    while status == "running":
        url = '%s/api/tasks/%s' % (add_http_prefix(host), task_id)
        args = {"index": index}
        try:
            _, data_str = http_get(url, args, auth, cafile)
        except urllib2.HTTPError, err:
            if err.code == 401:
                print("Authorization required")
                sys.exit(1)
            else:
                raise
        data = json.loads(data_str)
        index = data['index']
        status = data['status']

        for log in data['logs']:
            if verbose:
                print(log['message'])
            else:
                print('.', end='')
                sys.stdout.flush()

        if status == "error":
            print("Error: %s" % data['message'])
            sys.exit(1)

    if not verbose:
        print('')

def backups_ls_command(host, is_quiet, auth, cafile):
    url = '%s/api/backups' % add_http_prefix(host)

    try:
        _, data_str = http_get(url, None, auth, cafile)
    except urllib2.HTTPError, err:
        if err.code == 401:
            print("Authorization required")
            sys.exit(1)
        else:
            raise

    data = json.loads(data_str)

    result = []
    for backup_id, backup in data.items():
        result.append({
            'backup_id': backup_id,
            'group_id': str(backup['group_id']),
            'type': backup['type'],
            'size': "{0:.3f}".format(backup['size'] / 1024 ** 3),
            'mem_used': "{0:.3f}".format(backup['mem_used']),
            'time': backup['creation_time'].split('.')[0]
        })

    result = sorted(result, key=lambda x: x['time'], reverse=True)

    header = [
        ('backup_id', 'BACKUP'),
        ('group_id', 'GROUP'),
        ('type', 'TYPE'),
        ('size', 'SIZE'),
        ('mem_used', 'MEM USED'),
        ('time', 'TIME')
    ]

    if not is_quiet:
        print_table(header, result)
    else:
        groups = set([i['backup_id'] for i in result])
        print('\n'.join(groups))

def backups_download_command(host, backup_id, target_file,
                             auth, cafile, verbose):
    url = '%s/api/backups/%s/data' % (add_http_prefix(host), backup_id)

    try:
        _, stream = http_download(url, auth=auth, cafile=cafile)
    except urllib2.HTTPError, err:
        if err.code == 404:
            print("No such backup: '%s'" % backup_id)
            sys.exit(1)
        elif err.code == 401:
            print("Authorization required")
            sys.exit(1)
        else:
            raise

    total_size = int(stream.info().getheader('Content-Length').strip())
    bytes_read = 0
    chunk_size = 8192

    if verbose:
        progress_callback = print_upload_progress()
    else:
        progress_callback = print_upload_progress_silent()

    fobj = open(target_file, 'wb')

    while True:
        chunk = stream.read(chunk_size)

        if len(chunk) == 0:
            break

        fobj.write(chunk)
        bytes_read += len(chunk)

        progress_callback(float(bytes_read)/float(total_size))

    if not verbose:
        print('')


def backups_upload_command(host, group_id, group_type, backup_file,
                           auth, cafile, verbose):
    url = '%s/api/backups' % add_http_prefix(host)

    data = {'async': True,
            'type': group_type}

    if group_id:
        data['group_id'] = group_id

    backup_file = os.path.expanduser(backup_file)
    backup_file = os.path.realpath(backup_file)

    file_length = os.path.getsize(backup_file)
    fobj = open(backup_file)

    files = {'file': {'filename': 'backup.tar.gz',
                      'content': fobj,
                      'length': file_length}}

    progress_callback = None

    if verbose:
        progress_callback = print_upload_progress()
    else:
        progress_callback = print_upload_progress_silent()

    try:
        _, data_str = http_post(url, data, files=files,
                                auth=auth, cafile=cafile,
                                progress_callback=progress_callback)
    except urllib2.HTTPError, err:
        if err.code == 403:
            error_message = json.loads(err.read())['message']
            print("Error:", error_message)
            sys.exit(1)
        if err.code == 401:
            print("Authorization required")
            sys.exit(1)
        else:
            raise

    data = json.loads(data_str)
    task_id = data['task_id']
    backup_id = data.get('id', None)

    status = "running"
    index = 0
    while status == "running":
        url = '%s/api/tasks/%s' % (add_http_prefix(host), task_id)
        args = {"index": index}
        try:
            _, data_str = http_get(url, args, auth, cafile)
        except urllib2.HTTPError, err:
            if err.code == 401:
                print("Authorization required")
                sys.exit(1)
            else:
                raise
        data = json.loads(data_str)
        index = data['index']
        status = data['status']

        for log in data['logs']:
            if verbose:
                print(log['message'])
            else:
                print('.', end='')
                sys.stdout.flush()

        if status == "error":
            print("Error: %s" % data['message'])
            sys.exit(1)

    if not verbose:
        print('')

    if backup_id:
        print(backup_id)



def backups_rm_command(host, backup_id_list, auth, cafile, verbose):
    for backup_id in backup_id_list:
        url = '%s/api/backups/%s' % (add_http_prefix(host), backup_id)
        try:
            _, data_str = http_delete(url, {'async': True}, auth, cafile)
        except urllib2.HTTPError, err:
            if err.code == 500:
                data = json.loads(err.read())
                print("Failed remove backup: %s" % data['message'])
                sys.exit(1)
            if err.code == 404:
                print("No such backup: '%s'" % backup_id)
                sys.exit(1)
            elif err.code == 401:
                print("Authorization required")
                sys.exit(1)
            else:
                raise

        data = json.loads(data_str)
        task_id = data['task_id']

        status = "running"
        index = 0
        while status == "running":
            url = '%s/api/tasks/%s' % (add_http_prefix(host), task_id)
            args = {"index": index}
            try:
                _, data_str = http_get(url, args, auth, cafile)
            except urllib2.HTTPError, err:
                if err.code == 401:
                    print("Authorization required")
                    sys.exit(1)
                else:
                    raise
            data = json.loads(data_str)
            index = data['index']
            status = data['status']
            for log in data['logs']:
                if verbose:
                    print(log['message'])
                else:
                    print('.', end='')
                    sys.stdout.flush()

            if status == "error":
                print("Error: %s" % data['message'])
                sys.exit(1)

    if not verbose:
        print('')


def servers_ls_command(host, is_quiet, auth, cafile):
    url = '%s/api/servers' % add_http_prefix(host)

    try:
        _, data_str = http_get(url, None, auth, cafile)
    except urllib2.HTTPError, err:
        if err.code == 401:
            print("Authorization required")
            sys.exit(1)
        else:
            raise

    data = json.loads(data_str)

    result = []
    for addr, server in data.items():
        result.append({
            'addr': addr,
            'tags': ','.join(server['tags']),
            'status': colorize_state(server['state']['name'],
                                     server['state']['type']),
            'cpus': '%d' % server['cpus'],
            'memory': str(server['memory'])
        })

    result = sorted(result, key=lambda x: x['addr'])

    header = [
        ('addr', 'ADDR'),
        ('tags', 'TAGS'),
        ('status', 'STATE'),
        ('cpus', 'CPUS'),
        ('memory', 'MEMORY')
    ]

    if not is_quiet:
        print_table(header, result)
    else:
        groups = set([i['backup_id'] for i in result])
        print('\n'.join(groups))


def read_config():
    config = SafeConfigParser({'username': None, 'password': None,
                               'cafile': None})
    config.read(SETTINGS_PATH)

    result = {}

    for section in config.sections():
        result[section] = {}
        result[section]['username'] = config.get(section.decode('utf-8'), 'username')
        result[section]['password'] = config.get(section, 'password')
        result[section]['cafile'] = config.get(section, 'cafile')

    return result

def main():
    # Don't spam with HTTP connection logs from 'requests' module
    logging.getLogger("requests").setLevel(logging.WARNING)

    parser = argparse.ArgumentParser()

    parser.add_argument('-H', '--host',
                        default = None,
                        help='specify taas host to connect to')

    parser.add_argument('-v', '--verbose',
                        action='store_true',
                        default=False,
                        help='enable verbose output')

    parser.add_argument('-u', '--username',
                        dest='http_username',
                        help='User name for HTTP Basic Auth')

    parser.add_argument('-p', '--password',
                        dest='http_password',
                        help='Password for HTTP Basic Auth')

    parser.add_argument('-c', '--cafile',
                        help='CA file')

    subparsers = parser.add_subparsers(title="commands", dest="subparser_name")

    update_images_parser = subparsers.add_parser(
        'update_images', help='update docker images')

    ps_parser = subparsers.add_parser(
        'ps', help='show a list of running groups')
    ps_parser.add_argument(
        '-q', '--quiet',
        action='store_true',
        help='only show group IDs')

    inspect_parser = subparsers.add_parser(
        'inspect', help='inspect a group')
    inspect_parser.add_argument(
        'group_id',
        nargs='+',
        help='group to inspect')

    run_parser = subparsers.add_parser(
        'run', help='run a new group')
    run_parser.add_argument(
        '--name',
        help='name of the new group')
    run_parser.add_argument(
        '--memsize',
        type=float,
        help='amount of memory to allocate, in MiB (default is 500)',
        nargs='?',
        default=500)
    run_parser.add_argument(
        '--password',
        help='password for accessing this group')
    run_parser.add_argument(
        'type',
        help='instance type to run (default is memcached)',
        default='memcached', nargs='?')

    rm_parser = subparsers.add_parser(
        'rm', help='remove one or more groups')
    rm_parser.add_argument(
        'group_id',
        nargs='+',
        help='group to remove')

    update_parser = subparsers.add_parser(
        'update', help='update an existing group')
    update_parser.add_argument('--memsize',
                               type=float,
                               help='amount of memory to set',
                               default=None)
    update_parser.add_argument('--name',
                               help='name to set',
                               default=None)
    update_parser.add_argument('--config',
                               help='configuration file to update',
                               default=None)

    update_parser.add_argument(
        '--password',
        help='password for accessing this group via memcached protocol')

    update_parser.add_argument('group_id',
                               help='group ID to update')

    heal_parser = subparsers.add_parser(
        'heal', help='heal an existing group')
    heal_parser.add_argument('group_id',
                             help='group ID to heal')

    upgrade_parser = subparsers.add_parser(
        'upgrade', help='upgrade an existing group')
    upgrade_parser.add_argument('group_id',
                                help='group ID to upgrade')

    deploy_parser = subparsers.add_parser(
        'deploy', help='deploy configuration to an existing group')
    deploy_parser.add_argument('group_id',
                                help='group ID to deploy to')
    deploy_parser.add_argument('path',
                                help='path to deploy from')

    backup_parser = subparsers.add_parser(
        'backup', help='backup an existing group')
    backup_parser.add_argument('group_id',
                               help='group ID to backup')

    restore_parser = subparsers.add_parser(
        'restore', help='restore an existing group from backup')
    restore_parser.add_argument('group_id',
                                help='group ID to restore')
    restore_parser.add_argument('backup_id',
                                help='backup ID to restore from')

    backup_parser = subparsers.add_parser(
        'backups', help='manage backups')

    backup_subparsers = backup_parser.add_subparsers(
        title="commands",
        dest="backup_subparser_name")

    backup_ls_parser = backup_subparsers.add_parser('ls')
    backup_ls_parser.add_argument(
        '-q', '--quiet',
        action='store_true',
        help='only show backup IDs')

    backup_upload_parser = backup_subparsers.add_parser('upload')
    backup_upload_parser.add_argument(
        'type',
        help='instance type to upload backup for')

    backup_upload_parser.add_argument(
        'file',
        help='path to the backup tarball')

    backup_upload_parser.add_argument(
        'group_id',
        nargs='?',
        help='group ID to upload backup for')

    backup_download_parser = backup_subparsers.add_parser('download')
    backup_download_parser.add_argument(
        'backup_id',
        help='backup ID to download')

    backup_download_parser.add_argument(
        'file',
        help='file to download the backup to')

    backup_rm_parser = backup_subparsers.add_parser(
        'rm', help='remove one or more backups')
    backup_rm_parser.add_argument(
        'backup_id',
        nargs='+',
        help='backup to remove')

    servers_parser = subparsers.add_parser(
        'servers', help='manage servers')

    servers_subparsers = servers_parser.add_subparsers(
        title="commands",
        dest="servers_subparser_name")

    servers_ls_parser = servers_subparsers.add_parser('ls')
    servers_ls_parser.add_argument(
        '-q', '--quiet',
        action='store_true',
        help='only show server addresses')


    args = parser.parse_args()

    host = None
    if args.host is None:
        if 'TARANTOOL_CLOUD_HOST' in os.environ:
            host = os.environ['TARANTOOL_CLOUD_HOST']
        else:
            sys.exit("Please specify --host or pass TARANTOOL_CLOUD_HOST via env")
    else:
        host = args.host

    cfg = read_config()

    auth = None
    if args.http_username and args.http_password:
        auth = (args.http_username, args.http_password)
    elif host in cfg and 'username' in cfg[host] and 'password' in cfg[host]:
        auth = (cfg[host]['username'], cfg[host]['password'])

    cafile = None
    if args.cafile:
        cafile = args.cafile
    elif host in cfg:
        cafile = cfg[host]['cafile']

    if cafile:
        cafile = os.path.expanduser(cafile)

    if args.subparser_name == 'update_images':
        update_images_command(host, auth, cafile, args.verbose)
    elif args.subparser_name == 'ps':
        ps_command(host, args.quiet, auth, cafile)
    elif args.subparser_name == 'inspect':
        inspect_command(host, args.group_id, auth, cafile)
    elif args.subparser_name == 'run':
        run_command(host, args.type,
                    args.name, args.memsize, args.password,
                    auth, cafile, args.verbose)
    elif args.subparser_name == 'rm':
        rm_command(host, args.group_id, auth, cafile, args.verbose)
    elif args.subparser_name == 'update':
        update_command(host, args.group_id, args.name,
                       args.memsize, args.password, args.config, False,
                       auth, cafile, args.verbose)
    elif args.subparser_name == 'upgrade':
        upgrade_command(host, args.group_id, auth, cafile, args.verbose)
    elif args.subparser_name == 'heal':
        update_command(host, args.group_id, None,
                       None, None, None, True,
                       auth, cafile, args.verbose)
    elif args.subparser_name == 'deploy':
        update_command(host, args.group_id, None,
                       None, None, args.path, False,
                       auth, cafile, args.verbose)
    elif args.subparser_name == 'backup':
        backup_command(host, args.group_id, auth, cafile, args.verbose)
    elif args.subparser_name == 'restore':
        restore_command(host, args.group_id, args.backup_id, auth, cafile,
                        args.verbose)
    elif args.subparser_name == 'backups' and args.backup_subparser_name == 'ls':
        backups_ls_command(host, args.quiet, auth, cafile)
    elif args.subparser_name == 'backups' and args.backup_subparser_name == 'rm':
        backups_rm_command(host, args.backup_id, auth, cafile, args.verbose)
    elif args.subparser_name == 'backups' and args.backup_subparser_name == 'upload':
        backups_upload_command(host, args.group_id, args.type, args.file,
                               auth, cafile, args.verbose)
    elif args.subparser_name == 'backups' and args.backup_subparser_name == 'download':
        backups_download_command(host, args.backup_id, args.file,
                                 auth, cafile, args.verbose)
    elif args.subparser_name == 'servers' and args.servers_subparser_name == 'ls':
        servers_ls_command(host, args.quiet, auth, cafile)

if __name__ == '__main__':
    main()
